
'''
author：lixin
notes：结合本人面试经历，不可外传
'''

中国平安——实习生(上海/北京)

1.卷积正向和反向传播
2.Caffe源码
3.斐波那契 memcpy
4.pooling反向
5.项目介绍
6.override overload 纯虚函数等

阿里巴巴 2017.3.23 idst 非内推

1.linux 修改环境变量
2.sql语句
3.gbdt xgboost区别
4.kaggle项目 30min
5.融合方法，改进

阿里巴巴 2017.3.28 淘宝－搜索 内推

1.项目介绍(30分钟)--项目过程，融合方法，训练方法，augmentation等
2.batch normalization
3.有没有了解其他机器学习算法
4.介绍一个熟悉的算法(决策树)
5.在线写线性回归
6.对深度学习框架有没有了解，还是只是停留在使用的层面
7.有没有什么想问的

阿里巴巴 2017.3.31 淘宝－搜索 内推

1.项目介绍
2.kd-tree
3.开放问题  100w商品 50个推荐窗口，怎么安排推荐

腾讯 2017.4.10 - 非内推 - 一面

1.项目介绍
2.计算卷积核参数数量
3.如何处理深度学习overfitting
4.如何在测试中，加速1000倍(不改变网络结构)
5.pooling层的作用，以及为什么会选择maxpooling
6.有没有从头开始训练一个模型 vgg16 resnet googlenet收敛问题


今日头条 2017.4.11 - 日常 非内推 - 一面

1.项目介绍
2.如何训练深度学习网络
3.如何处理样本分布不均衡的问题
4.手写代码-反转链表 
5.手写代码-前序遍历

今日头条 2017.4.11 - 日常 非内推 - 二面

1.项目介绍（为什么不尝试xgboost以外的模型）
2.xgboost gbdt区别
3.深度学习训练方法
4.改进方法
5.caffe框架结构
6.手写代码-旋转数组找出最大数字

今日头条 2017.4.13 - 日常 非内推 - 三面

1.前两面反应较好，聊天
2.对前两个面试官有什么看法
3.有什么问题

腾讯游戏 - 内推校招 - 一面

	'''
	有二面的邀请，但是没有进行？
	'''
1.实习介绍
2.介绍svm，为什么要求对偶
3.介绍一个熟悉的算法
4.全局变量 局部变量存储位置不同，静态变量初始化，生存周期
5.python多线程的实现，死锁
6.优化算法 sgd 牛顿法。为什么牛顿法快？及其缺点？

#网易人工智能事业部
网易 - 内推校招 - 一面

1.实习介绍
2.kaggle 深度学习项目介绍
3.几个框架对比
4.模型融合策略和方法

网易 - 内推校招 - 二面

1.项目介绍，讲你最好的项目
2.实习介绍
3.svm手推
4.kaggle融合的策略和方法

#前3面反映较好，加面
网易 - 内推校招 - special 加面

1.最好的项目介绍
2.batch normalization算法
3.实习经历
4.cnn现在发展以及不足
5.说对游戏ai感兴趣 - alphago的技术点，强化学习等

华为 - 内推校招 - 1,2,3面
1.项目
2.实习
3.一些开发遇到的问题，如何解决

#Nvidia Deeplearning software 面试官很客气，提前定好这次面试时长40分钟
Nvidia - 内推校招 - 一面

1.项目介绍 30min
2.编程题2道
3.过拟合欠拟合 以及其背后本质，偏差方差角度如何理解


#Sensetime 商汤科技 每面30min
#号称最难进公司之一？
Sensetime 2017.9.11 - 内推校招 计算机视觉&深度学习 - 一面

1.kaggle比赛 问的比较详细  包括 data augmentation， KNN的trick， 模型融合等
2.实习经历
3.有什么问题

Sensetime 2017.9.11 - 内推校招 计算机视觉&深度学习 - 二面

1.kaggle比赛
2.头条实习
3.python set-list转化
4.caffe框架结构，learning rate设置
5.第K大的数
6.sgd adam区别
7.resnet vgg区别
8.python 变量拷贝规则
9.有什么要问的

Sensetime 2017.9.11 - 内推校招 计算机视觉&深度学习 - 三面

1.头条实习 比较详细以及为什么头条推荐这么厉害 #面试官是在做dl+推荐，所以比较关心头条所做的东西
2.熟悉什么框架
3.喜欢什么方向，cv还是推荐等，以及个人认为他们的前景
4.有什么问题


阿里巴巴 2017.9.13 - 校招 初面

1.头条实习 ----- 特征维度，为什么时延很低，在头条做了哪些，头条的算法
2.深度学习和传统机器学习
3.GBDT是什么 -- 加法模型
4.为什么现在推荐可以使用GBDT的内部结点当做LR的特征 -- 特征选择和子集评价，还是stack模型融合？
5.RF GBDT区别 -- 方差偏差理论，bagging&boost区别
6.GBDT xgboost区别 --泰勒二阶，并行化，正则项
7.手写MergeSort
8.熟悉什么语言
9.用什么框架
10.深度学习正则化
11.GBDT分布式如何实现 #没有了解过，然后简单说了自己的想法，面试官给我讲了许多这方面

阿里巴巴 2017.9.14 - 校招 终面

